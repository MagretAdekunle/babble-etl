{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a451d1f4-63aa-4306-b3d8-ea01fe7f645a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/anaconda3/lib/python3.12/site-packages (2.16.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.67.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting ast\n",
      "  Using cached AST-0.0.2.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[8 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/d8/yhrnl4gn78vbcvy365vfz_q00000gp/T/pip-install-fwzyq5ti/ast_971361bf801942ecb723dd854299390b/setup.py\", line 6, in <module>\n",
      "  \u001b[31m   \u001b[0m     README = codecs.open(os.path.join(here, 'AST/README'), encoding='utf8').read()\n",
      "  \u001b[31m   \u001b[0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"<frozen codecs>\", line 918, in open\n",
      "  \u001b[31m   \u001b[0m FileNotFoundError: [Errno 2] No such file or directory: '/private/var/folders/d8/yhrnl4gn78vbcvy365vfz_q00000gp/T/pip-install-fwzyq5ti/ast_971361bf801942ecb723dd854299390b/AST/README'\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting logging\n",
      "  Using cached logging-0.4.9.6.tar.gz (96 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[24 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 14, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/anaconda3/lib/python3.12/site-packages/setuptools/__init__.py\", line 22, in <module>\n",
      "  \u001b[31m   \u001b[0m     import _distutils_hack.override  # noqa: F401\n",
      "  \u001b[31m   \u001b[0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/anaconda3/lib/python3.12/site-packages/_distutils_hack/override.py\", line 1, in <module>\n",
      "  \u001b[31m   \u001b[0m     __import__('_distutils_hack').do_override()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/anaconda3/lib/python3.12/site-packages/_distutils_hack/__init__.py\", line 90, in do_override\n",
      "  \u001b[31m   \u001b[0m     ensure_local_distutils()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/anaconda3/lib/python3.12/site-packages/_distutils_hack/__init__.py\", line 76, in ensure_local_distutils\n",
      "  \u001b[31m   \u001b[0m     core = importlib.import_module('distutils.core')\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/anaconda3/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n",
      "  \u001b[31m   \u001b[0m     return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/anaconda3/lib/python3.12/site-packages/setuptools/_distutils/core.py\", line 13, in <module>\n",
      "  \u001b[31m   \u001b[0m     from .cmd import Command\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/anaconda3/lib/python3.12/site-packages/setuptools/_distutils/cmd.py\", line 7, in <module>\n",
      "  \u001b[31m   \u001b[0m     import logging\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/d8/yhrnl4gn78vbcvy365vfz_q00000gp/T/pip-install-1mtb_dfv/logging_3f5855059729405a91b12e616d5c46f9/logging/__init__.py\", line 618\n",
      "  \u001b[31m   \u001b[0m     raise NotImplementedError, 'emit must be implemented '\\\n",
      "  \u001b[31m   \u001b[0m                              ^\n",
      "  \u001b[31m   \u001b[0m SyntaxError: invalid syntax\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.12/site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: seaborn in /opt/anaconda3/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /opt/anaconda3/lib/python3.12/site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/anaconda3/lib/python3.12/site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /opt/anaconda3/lib/python3.12/site-packages (from seaborn) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install ast\n",
    "%pip install logging\n",
    "%pip install matplotlib\n",
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912159e1-e8a8-4ccf-99d6-22b4bd6e331a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import ast\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Data preprocessing function\n",
    "def preprocess_data(data_path):\n",
    "    # Read and preprocess data\n",
    "    df = pd.read_csv(data_path)\n",
    "    \n",
    "    # Convert string representations of lists to actual lists\n",
    "    df['Babbles'] = df['Babbles'].apply(ast.literal_eval)\n",
    "    \n",
    "    # Get sequences and pad them\n",
    "    sequences = df['Babbles'].values\n",
    "    padded_sequences = tf.keras.utils.pad_sequences(sequences, padding='post', dtype='float32')\n",
    "    \n",
    "    # Encode labels\n",
    "    le = LabelEncoder()\n",
    "    labels = le.fit_transform(df['Treatment'])\n",
    "    \n",
    "    return padded_sequences, labels, le.classes_\n",
    "\n",
    "# Create the LSTM model\n",
    "def create_lstm_model(max_length, num_classes):\n",
    "    model = tf.keras.Sequential([\n",
    "        # Input layer\n",
    "        tf.keras.layers.Input(shape=(max_length, 1)),\n",
    "        \n",
    "        # LSTM layers\n",
    "        tf.keras.layers.LSTM(128, return_sequences=True),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        \n",
    "        tf.keras.layers.LSTM(64),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        \n",
    "        # Dense layers with residual connections\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Custom callback for detailed training progress\n",
    "class TrainingCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch {epoch + 1}: loss = {logs[\"loss\"]:.4f}, '\n",
    "                  f'accuracy = {logs[\"accuracy\"]:.4f}, '\n",
    "                  f'val_loss = {logs[\"val_loss\"]:.4f}, '\n",
    "                  f'val_accuracy = {logs[\"val_accuracy\"]:.4f}')\n",
    "\n",
    "class TrainingVisualizer(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        super(TrainingVisualizer, self).__init__()\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_accuracies = []\n",
    "        self.val_accuracies = []\n",
    "        self.learning_rates = []\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.train_losses.append(logs['loss'])\n",
    "        self.val_losses.append(logs['val_loss'])\n",
    "        self.train_accuracies.append(logs['accuracy'])\n",
    "        self.val_accuracies.append(logs['val_accuracy'])\n",
    "        self.learning_rates.append(float(tf.keras.backend.get_value(self.model.optimizer.lr)))\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch {epoch + 1}: loss = {logs[\"loss\"]:.4f}, '\n",
    "                  f'accuracy = {logs[\"accuracy\"]:.4f}, '\n",
    "                  f'val_loss = {logs[\"val_loss\"]:.4f}, '\n",
    "                  f'val_accuracy = {logs[\"val_accuracy\"]:.4f}')\n",
    "\n",
    "def plot_training_history(visualizer, save_path=None):\n",
    "    plt.style.use('seaborn')\n",
    "    \n",
    "    # Create a figure with subplots\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    gs = fig.add_gridspec(2, 2)\n",
    "    \n",
    "    # Plot training & validation loss\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax1.plot(visualizer.train_losses, label='Training Loss', color='blue', alpha=0.7)\n",
    "    ax1.plot(visualizer.val_losses, label='Validation Loss', color='red', alpha=0.7)\n",
    "    ax1.set_title('Model Loss Over Time', pad=15)\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot training & validation accuracy\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax2.plot(visualizer.train_accuracies, label='Training Accuracy', color='blue', alpha=0.7)\n",
    "    ax2.plot(visualizer.val_accuracies, label='Validation Accuracy', color='red', alpha=0.7)\n",
    "    ax2.set_title('Model Accuracy Over Time', pad=15)\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot learning rate over time\n",
    "    ax3 = fig.add_subplot(gs[1, 0])\n",
    "    ax3.plot(visualizer.learning_rates, color='green', alpha=0.7)\n",
    "    ax3.set_title('Learning Rate Over Time', pad=15)\n",
    "    ax3.set_xlabel('Epoch')\n",
    "    ax3.set_ylabel('Learning Rate')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot loss vs accuracy\n",
    "    ax4 = fig.add_subplot(gs[1, 1])\n",
    "    ax4.scatter(visualizer.train_losses, visualizer.train_accuracies, \n",
    "                label='Training', alpha=0.5, color='blue')\n",
    "    ax4.scatter(visualizer.val_losses, visualizer.val_accuracies, \n",
    "                label='Validation', alpha=0.5, color='red')\n",
    "    ax4.set_title('Loss vs Accuracy', pad=15)\n",
    "    ax4.set_xlabel('Loss')\n",
    "    ax4.set_ylabel('Accuracy')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "def plot_sequence_prediction(sequence, prediction_probs, classes, save_path=None):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot sequence values\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(sequence, marker='o')\n",
    "    plt.title('Input Sequence')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Value')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot prediction probabilities\n",
    "    plt.subplot(1, 2, 2)\n",
    "    bars = plt.bar(classes, prediction_probs)\n",
    "    plt.title('Class Probabilities')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Add value labels on top of bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.4f}',\n",
    "                ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Set random seed for reproducibility\n",
    "    tf.random.set_seed(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Create timestamp for saving results\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    X, y, classes = preprocess_data('babbling_data.csv')\n",
    "    X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "    y = tf.keras.utils.to_categorical(y)\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Create and compile model (using the same model architecture as before)\n",
    "    model = create_lstm_model(X.shape[1], len(classes))\n",
    "    \n",
    "    # Learning rate schedule\n",
    "    initial_learning_rate = 0.001\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate, decay_steps=1000, decay_rate=0.9, staircase=True\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Initialize visualizer\n",
    "    visualizer = TrainingVisualizer()\n",
    "    \n",
    "    # Define callbacks\n",
    "    callbacks = [\n",
    "        visualizer,\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=20,\n",
    "            restore_best_weights=True,\n",
    "            min_delta=0.001\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=10,\n",
    "            min_lr=0.00001,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=150,\n",
    "        batch_size=32,\n",
    "        validation_split=0.2,\n",
    "        callbacks=callbacks,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Plot and save training history\n",
    "    plot_training_history(visualizer, f'training_history_{timestamp}.png')\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f'\\nTest accuracy: {test_accuracy:.4f}')\n",
    "    \n",
    "    # Make and visualize example prediction\n",
    "    sample_sequence = X_test[0].reshape(-1).tolist()\n",
    "    sequence = np.array(sample_sequence)\n",
    "    sequence = tf.keras.utils.pad_sequences([sequence], maxlen=X.shape[1], padding='post')\n",
    "    sequence = sequence.reshape(1, X.shape[1], 1)\n",
    "    \n",
    "    prediction = model.predict(sequence)\n",
    "    predicted_class = classes[np.argmax(prediction)]\n",
    "    confidence = np.max(prediction)\n",
    "    \n",
    "    print(f\"\\nExample prediction:\")\n",
    "    print(f\"Predicted class: {predicted_class}\")\n",
    "    print(f\"Confidence: {confidence:.4f}\")\n",
    "    \n",
    "    # Plot and save prediction visualization\n",
    "    plot_sequence_prediction(\n",
    "        sample_sequence,\n",
    "        prediction[0],\n",
    "        classes,\n",
    "        f'prediction_visualization_{timestamp}.png'\n",
    "    )\n",
    "    \n",
    "    return model, history, visualizer\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model, history, visualizer = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64e2ac8-98ad-4762-a924-1f5475275a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ... (previous imports and data preprocessing function remain the same)\n",
    "\n",
    "class TrainingVisualizer(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        super(TrainingVisualizer, self).__init__()\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_accuracies = []\n",
    "        self.val_accuracies = []\n",
    "        self.learning_rates = []\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.train_losses.append(logs['loss'])\n",
    "        self.val_losses.append(logs['val_loss'])\n",
    "        self.train_accuracies.append(logs['accuracy'])\n",
    "        self.val_accuracies.append(logs['val_accuracy'])\n",
    "        self.learning_rates.append(float(tf.keras.backend.get_value(self.model.optimizer.lr)))\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch {epoch + 1}: loss = {logs[\"loss\"]:.4f}, '\n",
    "                  f'accuracy = {logs[\"accuracy\"]:.4f}, '\n",
    "                  f'val_loss = {logs[\"val_loss\"]:.4f}, '\n",
    "                  f'val_accuracy = {logs[\"val_accuracy\"]:.4f}')\n",
    "\n",
    "def plot_training_history(visualizer, save_path=None):\n",
    "    plt.style.use('seaborn')\n",
    "    \n",
    "    # Create a figure with subplots\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    gs = fig.add_gridspec(2, 2)\n",
    "    \n",
    "    # Plot training & validation loss\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax1.plot(visualizer.train_losses, label='Training Loss', color='blue', alpha=0.7)\n",
    "    ax1.plot(visualizer.val_losses, label='Validation Loss', color='red', alpha=0.7)\n",
    "    ax1.set_title('Model Loss Over Time', pad=15)\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot training & validation accuracy\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax2.plot(visualizer.train_accuracies, label='Training Accuracy', color='blue', alpha=0.7)\n",
    "    ax2.plot(visualizer.val_accuracies, label='Validation Accuracy', color='red', alpha=0.7)\n",
    "    ax2.set_title('Model Accuracy Over Time', pad=15)\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot learning rate over time\n",
    "    ax3 = fig.add_subplot(gs[1, 0])\n",
    "    ax3.plot(visualizer.learning_rates, color='green', alpha=0.7)\n",
    "    ax3.set_title('Learning Rate Over Time', pad=15)\n",
    "    ax3.set_xlabel('Epoch')\n",
    "    ax3.set_ylabel('Learning Rate')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot loss vs accuracy\n",
    "    ax4 = fig.add_subplot(gs[1, 1])\n",
    "    ax4.scatter(visualizer.train_losses, visualizer.train_accuracies, \n",
    "                label='Training', alpha=0.5, color='blue')\n",
    "    ax4.scatter(visualizer.val_losses, visualizer.val_accuracies, \n",
    "                label='Validation', alpha=0.5, color='red')\n",
    "    ax4.set_title('Loss vs Accuracy', pad=15)\n",
    "    ax4.set_xlabel('Loss')\n",
    "    ax4.set_ylabel('Accuracy')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "def plot_sequence_prediction(sequence, prediction_probs, classes, save_path=None):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot sequence values\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(sequence, marker='o')\n",
    "    plt.title('Input Sequence')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Value')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot prediction probabilities\n",
    "    plt.subplot(1, 2, 2)\n",
    "    bars = plt.bar(classes, prediction_probs)\n",
    "    plt.title('Class Probabilities')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Add value labels on top of bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.4f}',\n",
    "                ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "def main():\n",
    "    # Set random seed for reproducibility\n",
    "    tf.random.set_seed(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Create timestamp for saving results\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    X, y, classes = preprocess_data('babbling_data.csv')\n",
    "    X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "    y = tf.keras.utils.to_categorical(y)\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Create and compile model (using the same model architecture as before)\n",
    "    model = create_lstm_model(X.shape[1], len(classes))\n",
    "    \n",
    "    # Learning rate schedule\n",
    "    initial_learning_rate = 0.001\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate, decay_steps=1000, decay_rate=0.9, staircase=True\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Initialize visualizer\n",
    "    visualizer = TrainingVisualizer()\n",
    "    \n",
    "    # Define callbacks\n",
    "    callbacks = [\n",
    "        visualizer,\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=20,\n",
    "            restore_best_weights=True,\n",
    "            min_delta=0.001\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=10,\n",
    "            min_lr=0.00001,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=150,\n",
    "        batch_size=32,\n",
    "        validation_split=0.2,\n",
    "        callbacks=callbacks,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Plot and save training history\n",
    "    plot_training_history(visualizer, f'training_history_{timestamp}.png')\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f'\\nTest accuracy: {test_accuracy:.4f}')\n",
    "    \n",
    "    # Make and visualize example prediction\n",
    "    sample_sequence = X_test[0].reshape(-1).tolist()\n",
    "    sequence = np.array(sample_sequence)\n",
    "    sequence = tf.keras.utils.pad_sequences([sequence], maxlen=X.shape[1], padding='post')\n",
    "    sequence = sequence.reshape(1, X.shape[1], 1)\n",
    "    \n",
    "    prediction = model.predict(sequence)\n",
    "    predicted_class = classes[np.argmax(prediction)]\n",
    "    confidence = np.max(prediction)\n",
    "    \n",
    "    print(f\"\\nExample prediction:\")\n",
    "    print(f\"Predicted class: {predicted_class}\")\n",
    "    print(f\"Confidence: {confidence:.4f}\")\n",
    "    \n",
    "    # Plot and save prediction visualization\n",
    "    plot_sequence_prediction(\n",
    "        sample_sequence,\n",
    "        prediction[0],\n",
    "        classes,\n",
    "        f'prediction_visualization_{timestamp}.png'\n",
    "    )\n",
    "    \n",
    "    return model, history, visualizer\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model, history, visualizer = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
