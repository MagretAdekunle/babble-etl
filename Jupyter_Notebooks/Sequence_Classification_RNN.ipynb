{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a451d1f4-63aa-4306-b3d8-ea01fe7f645a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install tensorflow\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install ast\n",
    "%pip install logging\n",
    "%pip install ast\n",
    "%pip install seaborn\n",
    "%pip install mlflow\n",
    "%pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af21f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba43b6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "def preprocess_data(data_path):\n",
    "    \"\"\"\n",
    "    Preprocesses the data by loading, validating, and filtering it.\n",
    "    Args: data_path (str): Path to the CSV file containing data.\n",
    "    Returns: tuple: (padded_sequences, labels, classes)\n",
    "    \"\"\"\n",
    "    logging.info('Starting data preprocessing')\n",
    "\n",
    "    try:\n",
    "        # Load the data\n",
    "        df = pd.read_csv(data_path)\n",
    "        \n",
    "        # Validate 'Babbles' column\n",
    "        required_columns = ['Babbles', 'Sex']\n",
    "        missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "        if missing_columns:\n",
    "            raise ValueError(f\"Missing columns: {missing_columns}\")\n",
    "        \n",
    "        # Convert strings to lists and filter by length\n",
    "        df['Babbles'] = df['Babbles'].apply(ast.literal_eval)\n",
    "        \n",
    "        df = df[df['Babbles'].apply(lambda x: 50 <= len(x) <= 1000)]\n",
    "\n",
    "        # Pad sequences\n",
    "        sequences = df['Babbles'].values\n",
    "        padded_sequences = tf.keras.utils.pad_sequences(sequences, padding='post', dtype='float32')\n",
    "        \n",
    "        # Encode labels\n",
    "        le = LabelEncoder()\n",
    "        labels = le.fit_transform(df['Sex'])\n",
    "        \n",
    "        logging.info(f'Processed {len(padded_sequences)} valid sequences with a length > 50')\n",
    "        return padded_sequences, labels, le.classes_\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"File {data_path} not found.\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error during preprocessing: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def create_model(input_length, num_classes):\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(input_length, 1)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes):\n",
    "    \"\"\"\n",
    "    Plots the confusion matrix.\n",
    "    \n",
    "    Args:\n",
    "        y_true (array): True labels.\n",
    "        y_pred (array): Predicted labels.\n",
    "        classes (list): Class names.\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Custom callback for detailed training progress\n",
    "class TrainingCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f'Epoch {epoch + 1}: loss = {logs[\"loss\"]:.4f}, '\n",
    "                  f'accuracy = {logs[\"accuracy\"]:.4f}, '\n",
    "                  f'val_loss = {logs[\"val_loss\"]:.4f}, '\n",
    "                  f'val_accuracy = {logs[\"val_accuracy\"]:.4f}')\n",
    "\n",
    "\n",
    "def handle_class_imbalance(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Handle class imbalance by applying oversampling, undersampling, or class weights.\n",
    "    \"\"\"\n",
    "    # Convert one-hot encoded labels back to integer labels (if needed)\n",
    "    y_train_labels = np.argmax(y_train, axis=1)\n",
    "    \n",
    "    # Log initial class distribution\n",
    "    class_counts = np.bincount(y_train_labels)\n",
    "    logging.info(f\"Initial class distribution in training data: {dict(zip(np.unique(y_train_labels), class_counts))}\")\n",
    "    \n",
    "    # If classes are imbalanced, apply oversampling, undersampling, or weighted loss\n",
    "    if np.any(class_counts < 0.1 * len(y_train_labels)):  # Example condition for imbalance (you can adjust the threshold)\n",
    "        logging.info(\"Class imbalance detected. Applying SMOTE oversampling.\")\n",
    "        smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train_labels)\n",
    "        y_train_resampled = tf.keras.utils.to_categorical(y_train_resampled, num_classes=y_train.shape[1])  # Convert back to one-hot encoding\n",
    "        # Log the new class distribution after resampling\n",
    "        new_class_counts = np.bincount(np.argmax(y_train_resampled, axis=1))\n",
    "        logging.info(f\"New class distribution after SMOTE oversampling: {dict(zip(np.unique(y_train_resampled), new_class_counts))}\")\n",
    "        return X_train_resampled, y_train_resampled, None\n",
    "    else:\n",
    "        # Calculate class weights for imbalanced classes\n",
    "        class_weights = compute_class_weight('balanced', classes=np.unique(y_train_labels), y=y_train_labels)\n",
    "        class_weights_dict = {i: weight for i, weight in zip(np.unique(y_train_labels), class_weights)}\n",
    "        # Log class weights distribution\n",
    "        logging.info(f\"Class weights: {class_weights_dict}\")\n",
    "        return X_train, y_train, class_weights_dict\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Preprocess data\n",
    "    try:\n",
    "        X, y, classes = preprocess_data('../CMBabble_Master_Sex_scm.csv')\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Preprocessing failed: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Reshape and split data\n",
    "    X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "    y = tf.keras.utils.to_categorical(y)\n",
    "    \n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Handle class imbalance (oversampling, undersampling, or class weights)\n",
    "    X_train, y_train, class_weights = handle_class_imbalance(X_train, y_train)\n",
    "\n",
    "    # Create and train model\n",
    "    model = create_model(X_train.shape[1], len(classes))\n",
    "\n",
    "    callbacks = [\n",
    "        TrainingCallback(),\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', \n",
    "            patience=35, \n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.3, \n",
    "            patience=25, \n",
    "            min_lr=0.0000005\n",
    "        ),\n",
    "        tf.keras.callbacks.TensorBoard(\n",
    "            log_dir='./logs', \n",
    "            histogram_freq=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=75,  # Adjust for practical training time\n",
    "        batch_size=32,\n",
    "        validation_split=0.2,\n",
    "        validation_data=(X_test, y_test),\n",
    "        callbacks=callbacks,\n",
    "        verbose=1,\n",
    "        class_weight=class_weights  # Apply class weights if available\n",
    "    )\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f\"\\nTest Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\\n\")\n",
    "\n",
    "    # Get predicted classes for all test samples\n",
    "    predictions = model.predict(X_test)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "    plot_confusion_matrix(true_classes, predicted_classes, classes)\n",
    "    print(classification_report(true_classes, predicted_classes, target_names=classes, zero_division=1))\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
