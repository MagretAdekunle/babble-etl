{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a451d1f4-63aa-4306-b3d8-ea01fe7f645a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install tensorflow\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install ast\n",
    "%pip install logging\n",
    "%pip install ast\n",
    "%pip install seaborn\n",
    "%pip install mlflow\n",
    "%pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af21f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba43b6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "def preprocess_data(data_path):\n",
    "    \"\"\"\n",
    "    Preprocesses the data by loading, validating, and filtering it.\n",
    "    Args: data_path (str): Path to the CSV file containing data.\n",
    "    Returns: tuple: (padded_sequences, labels, classes)\n",
    "    \"\"\"\n",
    "    logging.info('Starting data preprocessing')\n",
    "\n",
    "    try:\n",
    "        # Load the data\n",
    "        df = pd.read_csv(data_path)\n",
    "\n",
    "        # Validate required columns\n",
    "        required_columns = ['Babbles', 'Sex']\n",
    "        missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "        if missing_columns:\n",
    "            raise ValueError(f\"Missing columns: {missing_columns}\")\n",
    "\n",
    "        # Convert strings to lists and filter by length\n",
    "        df['Babbles'] = df['Babbles'].apply(ast.literal_eval)\n",
    "        df = df[df['Babbles'].apply(lambda x: 50 <= len(x))]\n",
    "\n",
    "        # Pad sequences\n",
    "        sequences = df['Babbles'].values\n",
    "        padded_sequences = tf.keras.utils.pad_sequences(sequences, padding='post', dtype='float32')\n",
    "\n",
    "        # Encode labels\n",
    "        le = LabelEncoder()\n",
    "        labels = le.fit_transform(df['Sex'])\n",
    "\n",
    "        logging.info(f'Processed {len(padded_sequences)} valid sequences with a length > 50')\n",
    "        return padded_sequences, labels, le.classes_\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"File {data_path} not found.\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error during preprocessing: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def focal_loss(gamma=2., alpha=0.25):\n",
    "    \"\"\"Focal loss for addressing class imbalance.\"\"\"\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        y_pred = tf.keras.backend.clip(y_pred, 1e-9, 1 - 1e-9)\n",
    "        loss = -alpha * (1 - y_pred) ** gamma * y_true * tf.keras.backend.log(y_pred)\n",
    "        return tf.keras.backend.mean(tf.keras.backend.sum(loss, axis=1))\n",
    "    return focal_loss_fixed\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Attention\n",
    "\n",
    "def create_model(input_length, num_classes):\n",
    "    input_seq = tf.keras.layers.Input(shape=(input_length, 1))\n",
    "\n",
    "    # First BiLSTM layer\n",
    "    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))(input_seq)\n",
    "\n",
    "    # Add attention layer\n",
    "    x = Attention()([x, x]) \n",
    "\n",
    "    # Second BiLSTM layer   \n",
    "    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64))(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "    # Dense Layer with L2 Regularization    \n",
    "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "    # x = tf.keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "    # Output Layer\n",
    "    output = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_seq, outputs=output)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss=focal_loss(),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes):\n",
    "    \"\"\"Plots the confusion matrix.\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "class TrainingCallback(tf.keras.callbacks.Callback):\n",
    "    \"\"\"Custom callback for detailed training progress.\"\"\"\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(\n",
    "            f'Epoch {epoch + 1}: loss = {logs[\"loss\"]:.4f}, '\n",
    "            f'accuracy = {logs[\"accuracy\"]:.4f}, '\n",
    "            f'val_loss = {logs[\"val_loss\"]:.4f}, '\n",
    "            f'val_accuracy = {logs[\"val_accuracy\"]:.4f}')\n",
    "\n",
    "\n",
    "def handle_class_imbalance(X_train, y_train):\n",
    "    \"\"\"Handle class imbalance by oversampling or weighting.\"\"\"\n",
    "    y_train_labels = np.argmax(y_train, axis=1)\n",
    "    class_counts = np.bincount(y_train_labels)\n",
    "    logging.info(f\"Initial class distribution in training data: {dict(zip(np.unique(y_train_labels), class_counts))}\")\n",
    "\n",
    "    if np.any(class_counts < 0.1 * len(y_train_labels)):\n",
    "        logging.info(\"Class imbalance detected. Applying SMOTE oversampling.\")\n",
    "        smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train_labels)\n",
    "        y_train_resampled = tf.keras.utils.to_categorical(y_train_resampled, num_classes=y_train.shape[1])\n",
    "        new_class_counts = np.bincount(np.argmax(y_train_resampled, axis=1))\n",
    "        logging.info(f\"New class distribution after SMOTE oversampling: {dict(zip(np.unique(y_train_resampled), new_class_counts))}\")\n",
    "        return X_train_resampled, y_train_resampled, None\n",
    "    else:\n",
    "        class_weights = compute_class_weight('balanced', classes=np.unique(y_train_labels), y=y_train_labels)\n",
    "        class_weights_dict = {i: weight for i, weight in zip(np.unique(y_train_labels), class_weights)}\n",
    "        logging.info(f\"Class weights: {class_weights_dict}\")\n",
    "        return X_train, y_train, class_weights_dict\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Preprocess data\n",
    "    try:\n",
    "        X, y, classes = preprocess_data('../CMBabble_Master_combined_scm.csv')\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Preprocessing failed: {e}\")\n",
    "        return\n",
    "\n",
    "    # Reshape and split data\n",
    "    X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "    y = tf.keras.utils.to_categorical(y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Handle class imbalance\n",
    "    X_train, y_train, class_weights = handle_class_imbalance(X_train, y_train)\n",
    "\n",
    "    # Create and train model\n",
    "    model = create_model(X_train.shape[1], len(classes))\n",
    "    \n",
    "    callbacks = [\n",
    "        TrainingCallback(),\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', \n",
    "            patience=10, \n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss', \n",
    "            factor=0.3,\n",
    "            patience=5, \n",
    "            min_lr=5e-7\n",
    "        ),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath='best_model.keras', \n",
    "            monitor='val_loss', \n",
    "            save_best_only=True, \n",
    "            verbose=1\n",
    "        ),\n",
    "        tf.keras.callbacks.TensorBoard(\n",
    "            log_dir='./logs',\n",
    "            histogram_freq=1\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=50, \n",
    "        batch_size=32,\n",
    "        validation_split=0.2,\n",
    "        validation_data=(X_test, y_test),\n",
    "        callbacks=callbacks,\n",
    "        verbose=1,\n",
    "        class_weight=class_weights\n",
    "    )\n",
    "\n",
    "    # Evaluate the model\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f\"\\nTest Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\\n\")\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "    plot_confusion_matrix(true_classes, predicted_classes, classes)\n",
    "    print(classification_report(true_classes, predicted_classes, target_names=classes, zero_division=1))\n",
    "\n",
    "    return model, history\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
