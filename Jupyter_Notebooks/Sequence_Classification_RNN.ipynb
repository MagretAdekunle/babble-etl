{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a451d1f4-63aa-4306-b3d8-ea01fe7f645a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install tensorflow\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install ast\n",
    "%pip install logging\n",
    "%pip install ast\n",
    "%pip install seaborn\n",
    "%pip install mlflow\n",
    "%pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5af21f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-10 10:18:01.472763: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba43b6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting data preprocessing\n",
      "INFO:root:Processed 555 valid sequences with a length > 50\n",
      "INFO:root:Initial class distribution in training data: {0: 183, 1: 261}\n",
      "INFO:root:Class weights: {0: 1.2131147540983607, 1: 0.8505747126436781}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not interpret metric identifier: val_loss",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 192\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model, history\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 192\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[5], line 164\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    143\u001b[0m model \u001b[38;5;241m=\u001b[39m create_model(X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mlen\u001b[39m(classes))\n\u001b[1;32m    145\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    146\u001b[0m     TrainingCallback(),\n\u001b[1;32m    147\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    162\u001b[0m ]\n\u001b[0;32m--> 164\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m    165\u001b[0m     X_train, y_train,\n\u001b[1;32m    166\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m75\u001b[39m,  \u001b[38;5;66;03m# Adjust for practical training time\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m    168\u001b[0m     validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[1;32m    169\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39m(X_test, y_test),\n\u001b[1;32m    170\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m    171\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    172\u001b[0m     class_weight\u001b[38;5;241m=\u001b[39mclass_weights  \u001b[38;5;66;03m# Apply class weights if available\u001b[39;00m\n\u001b[1;32m    173\u001b[0m )\n\u001b[1;32m    175\u001b[0m \u001b[38;5;66;03m# Evaluate on the test set\u001b[39;00m\n\u001b[1;32m    176\u001b[0m test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/metrics/__init__.py:206\u001b[0m, in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 206\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not interpret metric identifier: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midentifier\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Could not interpret metric identifier: val_loss"
     ]
    }
   ],
   "source": [
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "def preprocess_data(data_path):\n",
    "    \"\"\"\n",
    "    Preprocesses the data by loading, validating, and filtering it.\n",
    "    Args: data_path (str): Path to the CSV file containing data.\n",
    "    Returns: tuple: (padded_sequences, labels, classes)\n",
    "    \"\"\"\n",
    "    logging.info('Starting data preprocessing')\n",
    "\n",
    "    try:\n",
    "        # Load the data\n",
    "        df = pd.read_csv(data_path)\n",
    "        \n",
    "        # Validate 'Babbles' column\n",
    "        required_columns = ['Babbles', 'Sex']\n",
    "        missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "        if missing_columns:\n",
    "            raise ValueError(f\"Missing columns: {missing_columns}\")\n",
    "        \n",
    "        # Convert strings to lists and filter by length\n",
    "        df['Babbles'] = df['Babbles'].apply(ast.literal_eval)\n",
    "        \n",
    "        df = df[df['Babbles'].apply(lambda x: 50 <= len(x) <= 1000)]\n",
    "\n",
    "        # Pad sequences\n",
    "        sequences = df['Babbles'].values\n",
    "        padded_sequences = tf.keras.utils.pad_sequences(sequences, padding='post', dtype='float32')\n",
    "        \n",
    "        # Encode labels\n",
    "        le = LabelEncoder()\n",
    "        labels = le.fit_transform(df['Sex'])\n",
    "        \n",
    "        logging.info(f'Processed {len(padded_sequences)} valid sequences with a length > 50')\n",
    "        return padded_sequences, labels, le.classes_\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"File {data_path} not found.\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error during preprocessing: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def create_model(input_length, num_classes):\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(input_length, 1)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes):\n",
    "    \"\"\"\n",
    "    Plots the confusion matrix.\n",
    "    \n",
    "    Args:\n",
    "        y_true (array): True labels.\n",
    "        y_pred (array): Predicted labels.\n",
    "        classes (list): Class names.\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Custom callback for detailed training progress\n",
    "class TrainingCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f'Epoch {epoch + 1}: loss = {logs[\"loss\"]:.4f}, '\n",
    "                  f'accuracy = {logs[\"accuracy\"]:.4f}, '\n",
    "                  f'val_loss = {logs[\"val_loss\"]:.4f}, '\n",
    "                  f'val_accuracy = {logs[\"val_accuracy\"]:.4f}')\n",
    "\n",
    "\n",
    "def handle_class_imbalance(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Handle class imbalance by applying oversampling, undersampling, or class weights.\n",
    "    \"\"\"\n",
    "    # Convert one-hot encoded labels back to integer labels (if needed)\n",
    "    y_train_labels = np.argmax(y_train, axis=1)\n",
    "    \n",
    "    # Log initial class distribution\n",
    "    class_counts = np.bincount(y_train_labels)\n",
    "    logging.info(f\"Initial class distribution in training data: {dict(zip(np.unique(y_train_labels), class_counts))}\")\n",
    "    \n",
    "    # If classes are imbalanced, apply oversampling, undersampling, or weighted loss\n",
    "    if np.any(class_counts < 0.1 * len(y_train_labels)):  # Example condition for imbalance (you can adjust the threshold)\n",
    "        logging.info(\"Class imbalance detected. Applying SMOTE oversampling.\")\n",
    "        smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train_labels)\n",
    "        y_train_resampled = tf.keras.utils.to_categorical(y_train_resampled, num_classes=y_train.shape[1])  # Convert back to one-hot encoding\n",
    "        # Log the new class distribution after resampling\n",
    "        new_class_counts = np.bincount(np.argmax(y_train_resampled, axis=1))\n",
    "        logging.info(f\"New class distribution after SMOTE oversampling: {dict(zip(np.unique(y_train_resampled), new_class_counts))}\")\n",
    "        return X_train_resampled, y_train_resampled, None\n",
    "    else:\n",
    "        # Calculate class weights for imbalanced classes\n",
    "        class_weights = compute_class_weight('balanced', classes=np.unique(y_train_labels), y=y_train_labels)\n",
    "        class_weights_dict = {i: weight for i, weight in zip(np.unique(y_train_labels), class_weights)}\n",
    "        # Log class weights distribution\n",
    "        logging.info(f\"Class weights: {class_weights_dict}\")\n",
    "        return X_train, y_train, class_weights_dict\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Preprocess data\n",
    "    try:\n",
    "        X, y, classes = preprocess_data('../CMBabble_Master_Sex_scm.csv')\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Preprocessing failed: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Reshape and split data\n",
    "    X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "    y = tf.keras.utils.to_categorical(y)\n",
    "    \n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Handle class imbalance (oversampling, undersampling, or class weights)\n",
    "    X_train, y_train, class_weights = handle_class_imbalance(X_train, y_train)\n",
    "\n",
    "    # Create and train model\n",
    "    model = create_model(X_train.shape[1], len(classes))\n",
    "\n",
    "    callbacks = [\n",
    "        TrainingCallback(),\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', \n",
    "            patience=35, \n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.3, \n",
    "            patience=25, \n",
    "            min_lr=0.0000005\n",
    "        ),\n",
    "        tf.keras.callbacks.TensorBoard(\n",
    "            log_dir='./logs', \n",
    "            histogram_freq=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=75,  # Adjust for practical training time\n",
    "        batch_size=32,\n",
    "        validation_split=0.2,\n",
    "        validation_data=(X_test, y_test),\n",
    "        callbacks=callbacks,\n",
    "        verbose=1,\n",
    "        class_weight=class_weights  # Apply class weights if available\n",
    "    )\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f\"\\nTest Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\\n\")\n",
    "\n",
    "    # Get predicted classes for all test samples\n",
    "    predictions = model.predict(X_test)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "    plot_confusion_matrix(true_classes, predicted_classes, classes)\n",
    "    print(classification_report(true_classes, predicted_classes, target_names=classes, zero_division=1))\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
