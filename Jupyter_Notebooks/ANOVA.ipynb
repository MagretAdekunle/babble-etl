{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install ast\n",
    "%pip install logging\n",
    "%pip install dask\n",
    "%pip install gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import ast\n",
    "import dask.dataframe as dd\n",
    "from itertools import combinations\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "# Function to clean and prepare data\n",
    "def clean_and_prepare_data(csv_file):\n",
    "    data = pd.read_csv(csv_file)\n",
    "\n",
    "    # Convert date columns to datetime\n",
    "    # date_columns = ['Hatch date', 'Fledge date', 'Date on vocalization']\n",
    "    # for col in date_columns:\n",
    "    #     data[col] = pd.to_datetime(data[col], errors='coerce')\n",
    "    \n",
    "    # Replace spaces with underscores in the column names\n",
    "    data.columns = data.columns.str.replace(' ', '_')\n",
    "\n",
    "    # Extract statistics from 'Babbles' column\n",
    "    def process_babbles(babbles):\n",
    "        try:\n",
    "            babble_list = ast.literal_eval(babbles)  # Convert string to list\n",
    "            if isinstance(babble_list, list): \n",
    "                return {\n",
    "                    'babble_count': len(babble_list),\n",
    "                    'babble_mean': sum(babble_list) / len(babble_list) if babble_list else 0,\n",
    "                    'babble_sum': sum(babble_list),\n",
    "                }\n",
    "            else:\n",
    "                return {'babble_count': 0, 'babble_mean': 0, 'babble_sum': 0}\n",
    "        except (ValueError, SyntaxError):\n",
    "            return {'babble_count': 0, 'babble_mean': 0, 'babble_sum': 0}\n",
    "\n",
    "    babbles_stats = data['Babbles'].apply(process_babbles)\n",
    "    data['Babble_Length'] = babbles_stats.apply(lambda x: x['babble_count'])\n",
    "    data['Babble_Mean'] = babbles_stats.apply(lambda x: x['babble_mean'])\n",
    "    data['Babble_Sum'] = babbles_stats.apply(lambda x: x['babble_sum'])\n",
    "    \n",
    "    # Rename columns\n",
    "    data = data.rename(columns={'Bout_no.': 'Bout_number', 'No._eggs_hatched_from_nest': 'Number_eggs_hatched_from_nest', 'No._birds_fledged_from_nest': 'Number_birds_fledged_from_nest'})\n",
    "    \n",
    "    print(\"Cleaned columns:\", data.columns.tolist())\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "# Function to get header combinations\n",
    "def get_header_combinations(csv_file, exclude_headers=[]):\n",
    "    df = pd.read_csv(csv_file, nrows=0)  # Only reads headers\n",
    "    headers = df.columns.tolist()\n",
    "    \n",
    "    # Replace spaces with underscores\n",
    "    headers = [header.replace(' ', '_') for header in headers]\n",
    "    \n",
    "    # Exclude specified headers\n",
    "    filtered_headers = [header for header in headers if header not in exclude_headers]\n",
    "    \n",
    "    all_combinations = []\n",
    "    for r in range(1, len(filtered_headers) + 1):\n",
    "        combinations_r = list(combinations(filtered_headers, r))\n",
    "        all_combinations.extend(combinations_r)\n",
    "    \n",
    "    return all_combinations\n",
    "\n",
    "\n",
    "# Function to run ANOVA test for each combination\n",
    "def run_anova(data, combinations, response_col='Babble_Length'):\n",
    "    results = []\n",
    "    \n",
    "    for combo in combinations:\n",
    "        column_names = data[list(combo) + [response_col]]\n",
    "        \n",
    "        if column_names.isnull().sum().sum() > 0:\n",
    "            print(f\"Skipping combination {combo} due to missing data.\")\n",
    "            continue\n",
    "        \n",
    "        factors = column_names.columns[:-1]\n",
    "        response = column_names.columns[-1]\n",
    "        formula = f'{response} ~ ' + ' * '.join(factors)\n",
    "        \n",
    "        try:\n",
    "            model = ols(formula, data=column_names).fit()\n",
    "            anova_result = anova_lm(model)\n",
    "            anova_result['Combination'] = str(combo)\n",
    "            \n",
    "            # Write result to file immediately\n",
    "            anova_result.to_csv('partial_anova_results.csv', mode='a', header=False)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error running ANOVA for combination {combo}: {e}\")\n",
    "\n",
    "\n",
    "# Replace with your CSV file path\n",
    "csv_file = \"../CMBabble_Master_combined_scm.csv\"  \n",
    "# csv_file = \"../CMBabble_Master_clean.csv\"  \n",
    "\n",
    "\n",
    "# Clean and prepare the data\n",
    "data = clean_and_prepare_data(csv_file)\n",
    "\n",
    "# Get header combinations (excluding 'Babbles' column)\n",
    "exclude_headers = [\"Babbles\", \"Bout_ID\", \"Notes\", \"Raven work\", \"Date_on_vocalization_2\"]  \n",
    "header_combinations = get_header_combinations(csv_file, exclude_headers)\n",
    "print(\"Header combinations:\", header_combinations)\n",
    "\n",
    "# Run ANOVA on all combinations and save the results\n",
    "run_anova(data, header_combinations)\n",
    "\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('significant_anova_results.csv')\n",
    "\n",
    "# Filter rows where PR(>F) is less than or equal to 0.05\n",
    "df_filtered = df[df['PR(>F)'].notna() & (df['PR(>F)'] <= 0.05)]\n",
    "\n",
    "# Optionally, you can save the filtered DataFrame to a new CSV file\n",
    "df_filtered.to_csv('filtered_file.csv', index=False)\n",
    "print(\"\\nSignificant ANOVA results saved to 'filtered_file.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error running ANOVA for combination ('Hatch_date', 'Date_on_vocalization'): shapes (4,4128) and (3288,) not aligned: 4128 (dim 1) != 3288 (dim 0)\n",
      "Error running ANOVA for combination ('Nest_ID', 'Nestling', 'Hatch_date'): shapes (8,4032) and (3288,) not aligned: 4032 (dim 1) != 3288 (dim 0)\n",
      "Error running ANOVA for combination ('Nest_ID', 'Nestling', 'Date_on_vocalization'): shapes (8,7224) and (3288,) not aligned: 7224 (dim 1) != 3288 (dim 0)\n",
      "Error running ANOVA for combination ('Nest_ID', 'Audition_work', 'Hatch_date'): shapes (8,4032) and (3288,) not aligned: 4032 (dim 1) != 3288 (dim 0)\n",
      "Error running ANOVA for combination ('Nest_ID', 'Audition_work', 'Date_on_vocalization'): shapes (8,7224) and (3288,) not aligned: 7224 (dim 1) != 3288 (dim 0)\n",
      "Error running ANOVA for combination ('Nest_ID', 'Hatch_date', 'Fledge_date'): shapes (8,21888) and (3288,) not aligned: 21888 (dim 1) != 3288 (dim 0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from itertools import combinations\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "import gc\n",
    "\n",
    "# Function to clean and prepare a single chunk of data\n",
    "def clean_and_prepare_data(chunk):\n",
    "    # Convert date columns to datetime\n",
    "    date_columns = ['Hatch date', 'Fledge date', 'Date on vocalization']\n",
    "    for col in date_columns:\n",
    "        if col in chunk.columns:\n",
    "            chunk[col] = pd.to_datetime(chunk[col], errors='coerce')\n",
    "            print(f\"Converted column '{col}' to datetime:\")\n",
    "            print(chunk[col])\n",
    "            print(\"\\n\")  # Add a blank line for readability\n",
    "    \n",
    "\n",
    "    \n",
    "    # Replace spaces with underscores in the column names\n",
    "    chunk.columns = chunk.columns.str.replace(' ', '_')\n",
    "\n",
    "    # Extract statistics from 'Babbles' column\n",
    "    def process_babbles(babbles):\n",
    "        try:\n",
    "            babble_list = ast.literal_eval(babbles)  # Convert string to list\n",
    "            if isinstance(babble_list, list): \n",
    "                return {\n",
    "                    'babble_count': len(babble_list),\n",
    "                    'babble_mean': sum(babble_list) / len(babble_list) if babble_list else 0,\n",
    "                    'babble_sum': sum(babble_list),\n",
    "                }\n",
    "            else:\n",
    "                return {'babble_count': 0, 'babble_mean': 0, 'babble_sum': 0}\n",
    "        except (ValueError, SyntaxError):\n",
    "            return {'babble_count': 0, 'babble_mean': 0, 'babble_sum': 0}\n",
    "\n",
    "    if 'Babbles' in chunk.columns:\n",
    "        babbles_stats = chunk['Babbles'].apply(process_babbles)\n",
    "        chunk['Babble_Length'] = babbles_stats.apply(lambda x: x['babble_count'])\n",
    "        chunk['Babble_Mean'] = babbles_stats.apply(lambda x: x['babble_mean'])\n",
    "        chunk['Babble_Sum'] = babbles_stats.apply(lambda x: x['babble_sum'])\n",
    "\n",
    "    # Rename columns\n",
    "    chunk = chunk.rename(columns={\n",
    "        'Bout_no.': 'Bout_number', \n",
    "        'No._eggs_hatched_from_nest': 'Number_eggs_hatched_from_nest', \n",
    "        'No._birds_fledged_from_nest': 'Number_birds_fledged_from_nest'\n",
    "    })\n",
    "    \n",
    "    return chunk\n",
    "\n",
    "\n",
    "# Function to get header combinations\n",
    "def get_header_combinations(csv_file, exclude_headers=[]):\n",
    "    df = pd.read_csv(csv_file, nrows=0)  # Only reads headers\n",
    "    headers = df.columns.tolist()\n",
    "    \n",
    "    # Replace spaces with underscores\n",
    "    headers = [header.replace(' ', '_') for header in headers]\n",
    "    \n",
    "    # Exclude specified headers\n",
    "    filtered_headers = [header for header in headers if header not in exclude_headers]\n",
    "    \n",
    "    all_combinations = []\n",
    "    for r in range(1, len(filtered_headers) + 1):\n",
    "        combinations_r = list(combinations(filtered_headers, r))\n",
    "        all_combinations.extend(combinations_r)\n",
    "    \n",
    "    return all_combinations\n",
    "\n",
    "\n",
    "# Function to run ANOVA test for each combination\n",
    "def run_anova(chunk, combinations, response_col='Babble_Length'):\n",
    "    for combo in combinations:\n",
    "        try:\n",
    "            column_names = chunk[list(combo) + [response_col]]\n",
    "        except KeyError:\n",
    "            # Skip combinations with missing columns\n",
    "            continue\n",
    "        \n",
    "        # Check if there is enough data in the columns\n",
    "        if column_names.isnull().sum().sum() > 0:\n",
    "            print(f\"Skipping combination {combo} due to missing data.\")\n",
    "            continue\n",
    "        \n",
    "        # Construct the formula for the ANOVA\n",
    "        factors = column_names.columns[:-1]\n",
    "        response = column_names.columns[-1]\n",
    "        formula = f'{response} ~ ' + ' * '.join(factors)\n",
    "        \n",
    "        try:\n",
    "            # Run ANOVA\n",
    "            model = ols(formula, data=column_names).fit()\n",
    "            anova_result = anova_lm(model)\n",
    "            \n",
    "            # Add combination as an extra column\n",
    "            anova_result['Combination'] = str(combo)\n",
    "            \n",
    "            # Append results directly to a file in append mode\n",
    "            anova_result.to_csv('partial_anova_results.csv', mode='a', header=False)\n",
    "        except Exception as e:\n",
    "            print(f\"Error running ANOVA for combination {combo}: {e}\")\n",
    "\n",
    "\n",
    "# Function to filter significant results\n",
    "def filter_significant_results(file='partial_anova_results.csv', output_file='filtered_file.csv'):\n",
    "    # Load the results into a DataFrame\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    # Filter rows where PR(>F) is less than or equal to 0.05\n",
    "    df_filtered = df[df['PR(>F)'].notna() & (df['PR(>F)'] <= 0.05)]\n",
    "    \n",
    "    # Save the filtered results to a new CSV file\n",
    "    df_filtered.to_csv(output_file, index=False)\n",
    "    print(f\"\\nSignificant ANOVA results saved to '{output_file}'\")\n",
    "\n",
    "\n",
    "# Main execution block\n",
    "csv_file = \"../CMBabble_Master_clean.csv\"  # Replace with your file path\n",
    "chunksize = 50000  # Adjust chunk size as needed\n",
    "\n",
    "# Prepare header combinations (excluding specified columns)\n",
    "exclude_headers = [\"Babbles\", \"Bout_ID\", \"Notes\", \"Raven work\", \"Date_on_vocalization_2\", \"\"]  \n",
    "header_combinations = get_header_combinations(csv_file, exclude_headers)\n",
    "\n",
    "# Process the CSV file in chunks\n",
    "chunk_iter = pd.read_csv(csv_file, chunksize=chunksize)\n",
    "\n",
    "for chunk in chunk_iter:\n",
    "    # Clean and prepare the chunk\n",
    "    chunk = clean_and_prepare_data(chunk)\n",
    "    # Run ANOVA on the chunk\n",
    "    # run_anova(chunk, header_combinations)\n",
    "    # Collect garbage to free up memory\n",
    "    gc.collect()\n",
    "\n",
    "# Filter and save significant results\n",
    "filter_significant_results(file='partial_anova_results.csv', output_file='filtered_file.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
