{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install ast\n",
    "%pip install logging\n",
    "%pip install dask\n",
    "%pip install gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import logging\n",
    "import gc\n",
    "from itertools import combinations\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "def clean_and_prepare_data(chunk):\n",
    "    \"\"\"\n",
    "    Retrieve data from csv file to clean and prepare the entire dataset\n",
    "    :param chunk: The dataset\n",
    "    :return: The dataset that is clean and prepared\n",
    "    \"\"\"\n",
    "    logging.info('Starting to retrieve data to clean and prepare the entire dataset')\n",
    "\n",
    "    # Replace spaces with underscores in column names\n",
    "    chunk.columns = chunk.columns.str.replace(' ', '_')\n",
    "\n",
    "    # Extract statistics from 'Babbles' column (optimized with vectorized processing)\n",
    "    if 'Babbles' in chunk.columns:\n",
    "        def process_babbles_vectorized(babbles):\n",
    "            try:\n",
    "                babble_list = ast.literal_eval(babbles)\n",
    "                if isinstance(babble_list, list):\n",
    "                    return len(babble_list), sum(babble_list) / len(babble_list), sum(babble_list)\n",
    "                else:\n",
    "                    return 0, 0, 0\n",
    "            except (ValueError, SyntaxError):\n",
    "                return 0, 0, 0\n",
    "\n",
    "        babble_stats = chunk['Babbles'].apply(process_babbles_vectorized)\n",
    "        chunk[['Babble_Length', 'Babble_Mean', 'Babble_Sum']] = pd.DataFrame(babble_stats.tolist(), index=chunk.index)\n",
    "\n",
    "    # Rename columns\n",
    "    chunk = chunk.rename(columns={'Bout_no.': 'Bout_number'})\n",
    "\n",
    "    logging.info('Finished cleaning and preparing the entire dataset\\n')\n",
    "    return chunk\n",
    "\n",
    "\n",
    "def get_header_combinations(csv_file, exclude_headers=[]):\n",
    "    \"\"\"\n",
    "    Retrieve data from csv file to extract headers that will be used and some to exclude\n",
    "    :param csv_file: The path to the csv_file\n",
    "    :param exclude_headers: A list of headers to remove if needed\n",
    "    :return: A list of combinations to perform ANOVA Testing\n",
    "    \"\"\"\n",
    "    logging.info('Starting to extract headers that will be used and some to exclude')\n",
    "    df = pd.read_csv(csv_file, nrows=0) \n",
    "    headers = df.columns.str.replace(' ', '_').tolist()\n",
    "\n",
    "    filtered_headers = [header for header in headers if header not in exclude_headers]\n",
    "    logging.info('Finished extracting headers')\n",
    "\n",
    "    # Precompute all header combinations\n",
    "    all_combinations = [\n",
    "        comb for r in range(1, len(filtered_headers) + 1) \n",
    "        for comb in combinations(filtered_headers, r)\n",
    "    ]\n",
    "    logging.info('Finished finding all combinations for ANOVA Testing\\n')\n",
    "    return all_combinations\n",
    "\n",
    "\n",
    "def run_anova(chunk, combinations, response_col='Babble_Length'):\n",
    "    \"\"\"\n",
    "    Run ANOVA on a given chunk of data for each header combination.\n",
    "    :param chunk: Data chunk\n",
    "    :param combinations: Header combinations to test\n",
    "    :param response_col: The response column for the ANOVA\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    for combo in combinations:\n",
    "        try:\n",
    "            column_names = chunk[list(combo) + [response_col]]\n",
    "        except KeyError:\n",
    "            # Skip combinations with missing columns\n",
    "            continue\n",
    "        \n",
    "        # Check if there is enough data in the columns\n",
    "        if column_names.isnull().sum().sum() > 0:\n",
    "            logging.info(f\"Skipping combination {combo} due to missing data.\")\n",
    "            continue\n",
    "        \n",
    "        # Construct the formula for the ANOVA\n",
    "        factors = column_names.columns[:-1]\n",
    "        response = column_names.columns[-1]\n",
    "        formula = f'{response} ~ ' + ' * '.join(factors)\n",
    "        \n",
    "        try:\n",
    "            # Run ANOVA\n",
    "            model = ols(formula, data=column_names).fit()\n",
    "            anova_result = anova_lm(model)\n",
    "            \n",
    "            # Add combination as an extra column\n",
    "            anova_result['Combination'] = str(combo)\n",
    "            \n",
    "            # Append results directly to a file in append mode\n",
    "            anova_result.to_csv('partial_anova_results.csv', mode='a', header=False)\n",
    "        except Exception as e:\n",
    "            logging.info(f\"Error running ANOVA for combination {combo}: {e}\")\n",
    "\n",
    "\n",
    "def filter_significant_results(file='partial_anova_results.csv', output_file='filtered_file.csv'):\n",
    "    \"\"\"\n",
    "    Filters and saves significant results from ANOVA tests (PR(>F) <= 0.05).\n",
    "    :param file: Path to the CSV file containing ANOVA results\n",
    "    :param output_file: Path to save the filtered results\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    logging.info('Starting to filter rows where PR(>F) is less than or equal to 0.05')\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    # Filter rows where PR(>F) is less than or equal to 0.05\n",
    "    df_filtered = df[df['PR(>F)'].notna() & (df['PR(>F)'] <= 0.05)]\n",
    "    \n",
    "    # Save the filtered results to a new CSV file\n",
    "    df_filtered.to_csv(output_file, index=False)\n",
    "    logging.info(f\"Significant ANOVA results saved to '{output_file}'\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    csv_file = \"CMBabble_Master_combined.csv\" \n",
    "    chunksize = 50000 \n",
    "    exclude_headers = [\"Babbles\", \"Bout_ID\", \"Notes\", \"Raven work\", \"Date_on_vocalization_2\"]  \n",
    "    header_combinations = get_header_combinations(csv_file, exclude_headers)\n",
    "\n",
    "    # Process the CSV file in chunks\n",
    "    chunk_iter = pd.read_csv(csv_file, chunksize=chunksize)\n",
    "\n",
    "    for chunk in chunk_iter:\n",
    "        # Clean and prepare the chunk\n",
    "        chunk = clean_and_prepare_data(chunk)\n",
    "        # Run ANOVA on the chunk\n",
    "        run_anova(chunk, header_combinations)\n",
    "        # Collect garbage to free up memory\n",
    "        gc.collect()\n",
    "\n",
    "    # Filter and save significant results\n",
    "    filter_significant_results(file='partial_anova_results.csv', output_file='filtered_file.csv')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
