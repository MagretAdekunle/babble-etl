{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a451d1f4-63aa-4306-b3d8-ea01fe7f645a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (2.16.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from tensorflow) (4.25.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from tensorflow) (74.1.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from tensorflow) (1.67.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.0)\n",
      "Requirement already satisfied: rich in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting ast\n",
      "  Using cached AST-0.0.2.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[8 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/d8/yhrnl4gn78vbcvy365vfz_q00000gp/T/pip-install-jh1cmrs9/ast_9bd2d60360bc44aaba7372e609bfd20c/setup.py\", line 6, in <module>\n",
      "  \u001b[31m   \u001b[0m     README = codecs.open(os.path.join(here, 'AST/README'), encoding='utf8').read()\n",
      "  \u001b[31m   \u001b[0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"<frozen codecs>\", line 918, in open\n",
      "  \u001b[31m   \u001b[0m FileNotFoundError: [Errno 2] No such file or directory: '/private/var/folders/d8/yhrnl4gn78vbcvy365vfz_q00000gp/T/pip-install-jh1cmrs9/ast_9bd2d60360bc44aaba7372e609bfd20c/AST/README'\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting logging\n",
      "  Using cached logging-0.4.9.6.tar.gz (96 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[24 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 14, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages/setuptools/__init__.py\", line 22, in <module>\n",
      "  \u001b[31m   \u001b[0m     import _distutils_hack.override  # noqa: F401\n",
      "  \u001b[31m   \u001b[0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages/_distutils_hack/override.py\", line 1, in <module>\n",
      "  \u001b[31m   \u001b[0m     __import__('_distutils_hack').do_override()\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py\", line 90, in do_override\n",
      "  \u001b[31m   \u001b[0m     ensure_local_distutils()\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages/_distutils_hack/__init__.py\", line 76, in ensure_local_distutils\n",
      "  \u001b[31m   \u001b[0m     core = importlib.import_module('distutils.core')\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
      "  \u001b[31m   \u001b[0m     return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages/setuptools/_distutils/core.py\", line 13, in <module>\n",
      "  \u001b[31m   \u001b[0m     from .cmd import Command\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages/setuptools/_distutils/cmd.py\", line 7, in <module>\n",
      "  \u001b[31m   \u001b[0m     import logging\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/d8/yhrnl4gn78vbcvy365vfz_q00000gp/T/pip-install-_yrk572o/logging_138fb6b024fe4e47a503e0d578109aeb/logging/__init__.py\", line 618\n",
      "  \u001b[31m   \u001b[0m     raise NotImplementedError, 'emit must be implemented '\\\n",
      "  \u001b[31m   \u001b[0m                              ^\n",
      "  \u001b[31m   \u001b[0m SyntaxError: invalid syntax\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: seaborn in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from seaborn) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/MA57489/Parrots-Babbles/.venv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install ast\n",
    "%pip install logging\n",
    "%pip install matplotlib\n",
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "912159e1-e8a8-4ccf-99d6-22b4bd6e331a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 11:25:48.032187: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import logging\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb034f56-4f30-473f-8126-07953f6d3f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:561 rows remain after filtering\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - accuracy: 0.4763 - loss: 1.0530 - val_accuracy: 0.4444 - val_loss: 0.6933 - learning_rate: 0.0010\n",
      "Epoch 2/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.5134 - loss: 1.0243 - val_accuracy: 0.5556 - val_loss: 0.6923 - learning_rate: 0.0010\n",
      "Epoch 3/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 0.4441 - loss: 1.0382 - val_accuracy: 0.5556 - val_loss: 0.6924 - learning_rate: 0.0010\n",
      "Epoch 4/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 0.5736 - loss: 0.8115 - val_accuracy: 0.5556 - val_loss: 0.6914 - learning_rate: 0.0010\n",
      "Epoch 5/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4826 - loss: 0.8653Epoch 5: loss = 0.8767, accuracy = 0.4916, val_loss = 0.6891, val_accuracy = 0.5556\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 0.4833 - loss: 0.8662 - val_accuracy: 0.5556 - val_loss: 0.6891 - learning_rate: 0.0010\n",
      "Epoch 6/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.5582 - loss: 0.8154 - val_accuracy: 0.5556 - val_loss: 0.6892 - learning_rate: 0.0010\n",
      "Epoch 7/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.4743 - loss: 0.8984 - val_accuracy: 0.5556 - val_loss: 0.6903 - learning_rate: 0.0010\n",
      "Epoch 8/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 0.5707 - loss: 0.7990 - val_accuracy: 0.5556 - val_loss: 0.6908 - learning_rate: 0.0010\n",
      "Epoch 9/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.5383 - loss: 0.8438 - val_accuracy: 0.5556 - val_loss: 0.6888 - learning_rate: 0.0010\n",
      "Epoch 10/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5181 - loss: 0.8259Epoch 10: loss = 0.8508, accuracy = 0.4972, val_loss = 0.6892, val_accuracy = 0.5556\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.5165 - loss: 0.8278 - val_accuracy: 0.5556 - val_loss: 0.6892 - learning_rate: 0.0010\n",
      "Epoch 11/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.4598 - loss: 0.8103 - val_accuracy: 0.5556 - val_loss: 0.6924 - learning_rate: 0.0010\n",
      "Epoch 12/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.4812 - loss: 0.8154 - val_accuracy: 0.4444 - val_loss: 0.6938 - learning_rate: 0.0010\n",
      "Epoch 13/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.5059 - loss: 0.8314 - val_accuracy: 0.4444 - val_loss: 0.6950 - learning_rate: 0.0010\n",
      "Epoch 14/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 0.6001 - loss: 0.7027 - val_accuracy: 0.4444 - val_loss: 0.6993 - learning_rate: 0.0010\n",
      "Epoch 15/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5044 - loss: 0.7818Epoch 15: loss = 0.7827, accuracy = 0.5223, val_loss = 0.7055, val_accuracy = 0.4444\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 0.5058 - loss: 0.7819 - val_accuracy: 0.4444 - val_loss: 0.7055 - learning_rate: 0.0010\n",
      "Epoch 16/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 0.5077 - loss: 0.7943 - val_accuracy: 0.4444 - val_loss: 0.7178 - learning_rate: 0.0010\n",
      "Epoch 17/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 0.5913 - loss: 0.7351 - val_accuracy: 0.4444 - val_loss: 0.7090 - learning_rate: 0.0010\n",
      "Epoch 18/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 0.5524 - loss: 0.7410 - val_accuracy: 0.4444 - val_loss: 0.6991 - learning_rate: 0.0010\n",
      "Epoch 19/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5614 - loss: 0.7002\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 0.5610 - loss: 0.7006 - val_accuracy: 0.5556 - val_loss: 0.6922 - learning_rate: 0.0010\n",
      "Epoch 20/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5119 - loss: 0.7518Epoch 20: loss = 0.7595, accuracy = 0.4944, val_loss = 0.6959, val_accuracy = 0.4444\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 0.5106 - loss: 0.7524 - val_accuracy: 0.4444 - val_loss: 0.6959 - learning_rate: 5.0000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.5099 - loss: 0.7957 - val_accuracy: 0.4444 - val_loss: 0.6996 - learning_rate: 5.0000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.5623 - loss: 0.7236 - val_accuracy: 0.4444 - val_loss: 0.6979 - learning_rate: 5.0000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 0.4912 - loss: 0.7402 - val_accuracy: 0.4444 - val_loss: 0.7008 - learning_rate: 5.0000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.5765 - loss: 0.7546 - val_accuracy: 0.5556 - val_loss: 0.6927 - learning_rate: 5.0000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5724 - loss: 0.7058Epoch 25: loss = 0.7313, accuracy = 0.5335, val_loss = 0.6917, val_accuracy = 0.5556\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 0.5694 - loss: 0.7078 - val_accuracy: 0.5556 - val_loss: 0.6917 - learning_rate: 5.0000e-04\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 345ms/step - accuracy: 0.5355 - loss: 0.6909\n",
      "\n",
      "Test accuracy: 0.5575\n",
      "Test loss: 0.6889\n",
      "\n",
      "\n",
      "Example prediction:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step\n",
      "Sample 1:\n",
      "Predicted class: M\n",
      "Confidence: 0.5232\n",
      "Class probabilities: {'F': '0.4768', 'M': '0.5232'}\n",
      "True class: F\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step\n",
      "Sample 2:\n",
      "Predicted class: M\n",
      "Confidence: 0.5232\n",
      "Class probabilities: {'F': '0.4768', 'M': '0.5232'}\n",
      "True class: M\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step\n",
      "Sample 3:\n",
      "Predicted class: M\n",
      "Confidence: 0.5232\n",
      "Class probabilities: {'F': '0.4768', 'M': '0.5232'}\n",
      "True class: M\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step\n",
      "Sample 4:\n",
      "Predicted class: M\n",
      "Confidence: 0.5232\n",
      "Class probabilities: {'F': '0.4768', 'M': '0.5232'}\n",
      "True class: M\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step\n",
      "Sample 5:\n",
      "Predicted class: M\n",
      "Confidence: 0.5232\n",
      "Class probabilities: {'F': '0.4768', 'M': '0.5232'}\n",
      "True class: F\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Data preprocessing function\n",
    "def preprocess_data(data_path):\n",
    "    # Read and preprocess data\n",
    "    df = pd.read_csv(data_path)\n",
    "    \n",
    "    # Convert string representations of lists to actual lists\n",
    "    df['Babbles'] = df['Babbles'].apply(ast.literal_eval)\n",
    "\n",
    "    df = df[df['Babbles'].apply(lambda x: len(x) >= 50)]\n",
    "    logging.info(f'{len(df)} rows remain after filtering')\n",
    "    \n",
    "    # Get sequences and pad them\n",
    "    sequences = df['Babbles'].values\n",
    "    padded_sequences = tf.keras.utils.pad_sequences(sequences, padding='post', dtype='float32')\n",
    "\n",
    "    # Encode labels\n",
    "    le = LabelEncoder()\n",
    "    labels = le.fit_transform(df['Sex'])\n",
    "    \n",
    "    return padded_sequences, labels, le.classes_\n",
    "\n",
    "# Create the LSTM model\n",
    "def create_lstm_model(max_length, num_classes):\n",
    "    model = tf.keras.Sequential([\n",
    "        # Input layer\n",
    "        tf.keras.layers.Input(shape=(max_length, 1)),\n",
    "        \n",
    "        # LSTM layers\n",
    "        tf.keras.layers.LSTM(128, return_sequences=True),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        \n",
    "        tf.keras.layers.LSTM(64),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        \n",
    "        # Dense layers with residual connections\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Custom callback for detailed training progress\n",
    "class TrainingCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f'Epoch {epoch + 1}: loss = {logs[\"loss\"]:.4f}, '\n",
    "                  f'accuracy = {logs[\"accuracy\"]:.4f}, '\n",
    "                  f'val_loss = {logs[\"val_loss\"]:.4f}, '\n",
    "                  f'val_accuracy = {logs[\"val_accuracy\"]:.4f}')\n",
    "\n",
    "def main():\n",
    "    # Set random seed for reproducibility\n",
    "    tf.random.set_seed(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    X, y, classes = preprocess_data('../CMBabble_Master_Sex_scm.csv')\n",
    "    \n",
    "    # Reshape input for LSTM (samples, time steps, features)\n",
    "    X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "    \n",
    "    # Convert labels to one-hot encoding\n",
    "    y = tf.keras.utils.to_categorical(y)\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Create and compile the model\n",
    "    model = create_lstm_model(X.shape[1], len(classes))\n",
    "    \n",
    "    # Use a fixed initial learning rate with ReduceLROnPlateau\n",
    "    initial_learning_rate = 0.001\n",
    "    \n",
    "    # Compile the model with fixed learning rate\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=initial_learning_rate),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Define callbacks\n",
    "    callbacks = [\n",
    "        TrainingCallback(),\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=20,\n",
    "            restore_best_weights=True,\n",
    "            min_delta=0.001\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=10,\n",
    "            min_lr=0.00001,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=150,  # Increased epochs since we have early stopping\n",
    "        batch_size=32,\n",
    "        validation_split=0.2,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f'Test loss: {test_loss:.4f}\\n')\n",
    "    print(f'\\nTest accuracy: {test_accuracy:.4f}')\n",
    "    \n",
    "    # Function to predict on new sequences\n",
    "    def predict_sequence(sequence):\n",
    "        # Ensure sequence is in correct format\n",
    "        sequence = np.array(sequence)\n",
    "        sequence = tf.keras.utils.pad_sequences([sequence], maxlen=X.shape[1], padding='post')\n",
    "        sequence = sequence.reshape(1, X.shape[1], 1)\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = model.predict(sequence)\n",
    "        predicted_class = classes[np.argmax(prediction)]\n",
    "        confidence = np.max(prediction)\n",
    "        \n",
    "        return predicted_class, confidence, prediction[0]\n",
    "\n",
    "    # Example prediction\n",
    "    print(\"\\nExample prediction:\")\n",
    "    for i in range(5):  # Predicting for the first 5 test samples\n",
    "        sample_sequence = X_test[i].reshape(-1).tolist()\n",
    "        pred_class, confidence, class_probabilities = predict_sequence(sample_sequence)\n",
    "        print(f\"Sample {i + 1}:\")\n",
    "        print(f\"Predicted class: {pred_class}\")\n",
    "        print(f\"Confidence: {confidence:.4f}\")\n",
    "        print(\"Class probabilities:\", {c: f\"{p:.4f}\" for c, p in zip(classes, class_probabilities)})\n",
    "\n",
    "        # Optionally, print the true class to compare\n",
    "        true_class = classes[np.argmax(y_test[i])]\n",
    "        print(f\"True class: {true_class}\\n\")\n",
    "    \n",
    "    return model, history, predict_sequence\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
